{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xyqdJDGiuStN"
   },
   "source": [
    "# Complete notebook with code to generate all the results (Group 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions for the notebook:\n",
    "- In the cell below the imports, the dataset has to be chosen, by uncommenting one of the assignment statements\n",
    "- After the necessary directories have been created, *all* the datasets can be downloaded from our github (under \"Download datasets\"). This only needs to happen once, after that the cell can be commented. \n",
    "- The rest of the cells can be run without input or changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sc1wRCCLuStS"
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from math import ceil\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import pickle \n",
    "import scipy.ndimage\n",
    "from PIL import Image as PILImage\n",
    "from skimage.color import rgb2gray\n",
    "import glob\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xVCUJ_XiuSto"
   },
   "source": [
    "## Choose the dataset here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eKoKOBNQuStq"
   },
   "outputs": [],
   "source": [
    "# Uncomment one of the assignments below\n",
    "\n",
    "# WHICH_DATA_FLAG = \"mnist_original\"\n",
    "WHICH_DATA_FLAG = \"cifar\"\n",
    "# WHICH_DATA_FLAG = \"mnist_color\"\n",
    "# WHICH_DATA_FLAG = \"mnist_rgb2gray\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LhBVEiXquSta"
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5sXJOMTuStc"
   },
   "outputs": [],
   "source": [
    "# borrowed from the original paper of Li et al. (2018)\n",
    "def makedirs(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def list_of_norms(X):\n",
    "    return torch.sum(torch.pow(X, 2), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ESm8gfRQuSti"
   },
   "source": [
    "## Create necessary directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "33TgrqgcuStj"
   },
   "outputs": [],
   "source": [
    "# data folder\n",
    "data_folder = os.path.join(os.getcwd(), \"data\")\n",
    "makedirs(data_folder)\n",
    "\n",
    "# Various model folders\n",
    "model_original = os.path.join(os.getcwd(), \"models\", \"mnist_original\")\n",
    "model_cifar = os.path.join(os.getcwd(), \"models\", \"cifar\")\n",
    "model_mnist_color = os.path.join(os.getcwd(), \"models\", \"mnist_color\")\n",
    "model_mnist_rgb2gray = os.path.join(os.getcwd(), \"models\", \"mnist_rgb2gray\")\n",
    "\n",
    "model_folders_list = [model_original, model_cifar, model_mnist_color, model_mnist_rgb2gray]\n",
    "\n",
    "# Image folder in every model folder\n",
    "for model_folder in model_folders_list:\n",
    "    makedirs(os.path.join(model_folder, \"img\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download datasets\n",
    "Run the cell below once to download the necessary MNIST datasets. After that it can be commented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "968klvOGuSuG"
   },
   "outputs": [],
   "source": [
    "# gdd.download_file_from_google_drive(file_id='1fgjFKJ1_2VaPbKROeH-aZJiX52eetw9w',\n",
    "#                                     dest_path='./data/github_data.zip',\n",
    "#                                     unzip=True, showsize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5fE4zTqyuStu"
   },
   "source": [
    "## Parameters dependent on dataset, no input needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oLk4PIj5uStv"
   },
   "outputs": [],
   "source": [
    "batch_size = 250\n",
    "n_input_channels = 1\n",
    "image_size = 28\n",
    "if WHICH_DATA_FLAG == \"mnist_original\":\n",
    "    model_folder = model_original\n",
    "    model_filename = \"mnist_original\"\n",
    "elif WHICH_DATA_FLAG == \"mnist_color\":\n",
    "    model_folder = model_mnist_color\n",
    "    model_filename = \"mnist_color\"\n",
    "    n_input_channels = 3\n",
    "elif WHICH_DATA_FLAG == \"mnist_rgb2gray\":\n",
    "    model_folder = model_mnist_rgb2gray\n",
    "    model_filename = \"mnist_rgb2gray\"\n",
    "elif WHICH_DATA_FLAG == \"cifar\":\n",
    "    model_folder = model_cifar\n",
    "    model_filename = \"cifar\"\n",
    "    n_input_channels = 3\n",
    "    image_size = 32\n",
    "\n",
    "img_folder = os.path.join(model_folder, \"img\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1dS-h4VbuSt0"
   },
   "source": [
    "## Helper functions to load cifar (borrowed from Deep Learning Assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "av_BDImwuSt1"
   },
   "outputs": [],
   "source": [
    "# all code in this cell borrowed from deep learning assignment\n",
    "\n",
    "def load_cifar10_batch(batch_filename):\n",
    "    with open(batch_filename, 'rb') as f:\n",
    "        batch = pickle.load(f, encoding='latin1')\n",
    "        X = batch['data']\n",
    "        Y = batch['labels']\n",
    "        X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(np.float32)\n",
    "        Y = np.array(Y)\n",
    "        return X, Y\n",
    "\n",
    "def load_cifar10(cifar10_folder):\n",
    "    Xs = []\n",
    "    Ys = []\n",
    "    for b in range(1, 6):\n",
    "        batch_filename = os.path.join(cifar10_folder, 'data_batch_' + str(b))\n",
    "        X, Y = load_cifar10_batch(batch_filename)\n",
    "        Xs.append(X)\n",
    "        Ys.append(Y)\n",
    "    X_train = np.concatenate(Xs)\n",
    "    Y_train = np.concatenate(Ys)\n",
    "    X_test, Y_test = load_cifar10_batch(os.path.join(cifar10_folder, 'test_batch'))\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "def get_cifar10_raw_data(data_dir):\n",
    "    X_train, Y_train, X_test, Y_test = load_cifar10(data_dir)\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "def preprocess_cifar10_data(X_train_raw, Y_train_raw, X_test_raw, Y_test_raw):\n",
    "    X_train = X_train_raw.copy()\n",
    "    Y_train = Y_train_raw.copy()\n",
    "    X_test = X_test_raw.copy()\n",
    "    Y_test = Y_test_raw.copy()\n",
    "    \n",
    "    # Transpose\n",
    "    X_train = np.transpose(X_train, (0, 3, 1, 2))\n",
    "    X_test = np.transpose(X_test, (0, 3, 1, 2))\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "def dense_to_one_hot(labels_dense, num_classes):\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_one_hot\n",
    "\n",
    "class DataSet(object):\n",
    "    def __init__(self, images, labels):\n",
    "        assert images.shape[0] == labels.shape[0], (\n",
    "          \"images.shape: {0}, labels.shape: {1}\".format(str(images.shape), str(labels.shape)))\n",
    "\n",
    "        self._num_examples = images.shape[0]\n",
    "        self._images = images\n",
    "        self._labels = labels\n",
    "        self._epochs_completed = 0\n",
    "        self._index_in_epoch = 0\n",
    "\n",
    "    @property\n",
    "    def images(self):\n",
    "        return self._images\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._labels\n",
    "\n",
    "    @property\n",
    "    def num_examples(self):\n",
    "        return self._num_examples\n",
    "\n",
    "    @property\n",
    "    def epochs_completed(self):\n",
    "        return self._epochs_completed\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        start = self._index_in_epoch\n",
    "        self._index_in_epoch += batch_size\n",
    "        if self._index_in_epoch > self._num_examples:\n",
    "            self._epochs_completed += 1\n",
    "\n",
    "            perm = np.arange(self._num_examples)\n",
    "            np.random.shuffle(perm)\n",
    "            self._images = self._images[perm]\n",
    "            self._labels = self._labels[perm]\n",
    "\n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size\n",
    "            assert batch_size <= self._num_examples\n",
    "\n",
    "        end = self._index_in_epoch\n",
    "        return self._images[start:end], self._labels[start:end]\n",
    "\n",
    "def read_data_sets(data_dir, one_hot = True, validation_size = 5000):\n",
    "    # Extract CIFAR10 data\n",
    "    train_images_raw, train_labels_raw, test_images_raw, test_labels_raw = \\\n",
    "        get_cifar10_raw_data(data_dir)\n",
    "    train_images, train_labels, test_images, test_labels = \\\n",
    "        preprocess_cifar10_data(train_images_raw, train_labels_raw, test_images_raw, test_labels_raw)\n",
    "\n",
    "    # Apply one-hot encoding if specified\n",
    "    if one_hot:\n",
    "        num_classes = len(np.unique(train_labels))\n",
    "        train_labels = dense_to_one_hot(train_labels, num_classes)\n",
    "        test_labels = dense_to_one_hot(test_labels, num_classes)\n",
    "\n",
    "    # Subsample the validation set from the train set\n",
    "    if not 0 <= validation_size <= len(train_images):\n",
    "        raise ValueError(\"Validation size should be between 0 and {0}. Received: {1}.\".format(\n",
    "            len(train_images), validation_size))\n",
    "\n",
    "    validation_images = train_images[:validation_size]\n",
    "    validation_labels = train_labels[:validation_size]\n",
    "    train_images = train_images[validation_size:]\n",
    "    train_labels = train_labels[validation_size:]\n",
    "\n",
    "    # Create datasets\n",
    "    train = DataSet(train_images, train_labels)\n",
    "    validation = DataSet(validation_images, validation_labels)\n",
    "    test = DataSet(test_images, test_labels)\n",
    "\n",
    "    return {'train': train, 'validation': validation, 'test': test}\n",
    "\n",
    "#changed data_dir = cifar_folder -> data_dir\n",
    "def get_cifar10(data_dir, one_hot = True, validation_size = 5000):\n",
    "    return read_data_sets(data_dir, one_hot, validation_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szlpORCJuSt6"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "onRgMG-ruSt7"
   },
   "source": [
    "## Function to transform original MNIST to colored MNIST or rgb2gray MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-W-Ia3BMuSt8"
   },
   "outputs": [],
   "source": [
    "def color_dataset(raw_data, to_gray=False):\n",
    "    N = len(raw_data)\n",
    "    if to_gray:\n",
    "        n_channels = 1\n",
    "    else:\n",
    "        n_channels = 3\n",
    "    \n",
    "    raw_data = raw_data.view(N, 28, 28, 1)\n",
    "    \n",
    "    try:\n",
    "        lena = PILImage.open('./resources/lena.png')    \n",
    "    except:\n",
    "        print(\"Lena image could not be found, please check ./resources/lena.png\")\n",
    "        return 1\n",
    "            \n",
    "\n",
    "    # Extend to RGB\n",
    "    data_rgb = np.concatenate([raw_data, raw_data, raw_data], axis=3)\n",
    "    \n",
    "    # Make binary\n",
    "    data_binary = (data_rgb > 0.5)\n",
    "    data_color = np.zeros((N, 28, 28, n_channels))\n",
    "    \n",
    "    for i in range(N):\n",
    "        # Take a random crop of the Lena image (background)\n",
    "        x_c = np.random.randint(0, lena.size[0] - 28)\n",
    "        y_c = np.random.randint(0, lena.size[1] - 28)\n",
    "        image = lena.crop((x_c, y_c, x_c + 28, y_c + 28))\n",
    "        image = np.asarray(image) # / 255.0 REMOVED DIVISION HERE TO MAKE EVERY DATASET EQUAL\n",
    "\n",
    "        ## COPIED IMAGE BECAUSE \"READ-ONLY\" ERROR\n",
    "        new_image = image.copy()\n",
    "        # Change color distribution # SHOULD THIS ONLY HAPPEN IF TO_GRAY == FALSE?\n",
    "        for j in range(3):\n",
    "            new_image[:, :, j] = (new_image[:, :, j] + np.random.uniform(0, 1)) / 2.0\n",
    "\n",
    "        # Invert the colors at the location of the number\n",
    "        new_image[data_binary[i]] = 1 - new_image[data_binary[i]]\n",
    "        if to_gray:\n",
    "            data_color[i] = np.reshape(rgb2gray(new_image), (28, 28, 1))\n",
    "        else:\n",
    "            data_color[i] = new_image\n",
    "        \n",
    "    return torch.from_numpy(data_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "37FYDtEduSuA"
   },
   "source": [
    "## Load the datasets\n",
    "The function below describes how the data can be generated. This function is not used in the notebook. The data used in this notebook is stored on the github repository for reproducibility purposes. When generating the data yourself, every dataset will differ slightly as a result of the randomly generated backgrounds and colors for MNIST color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IbJd3XkmuSuB"
   },
   "outputs": [],
   "source": [
    "def get_data(data_flag):\n",
    "    # check if flag is correct\n",
    "    assert data_flag in [\"mnist_original\", \"cifar\", \"mnist_color\", \"mnist_rgb2gray\"]\n",
    "    \n",
    "    if data_flag == \"cifar\":\n",
    "        # extract cifar data\n",
    "        data = get_cifar10(os.path.join(data_folder, \"cifar\"), one_hot=False)\n",
    "\n",
    "        # extract training,validation and test data\n",
    "        X_train, Y_train = torch.from_numpy(data['train'].images), torch.from_numpy(data['train'].labels)\n",
    "        X_validation, Y_validation = torch.from_numpy(data['validation'].images), torch.from_numpy(data['validation'].labels)\n",
    "        X_test, Y_test = torch.from_numpy(data['test'].images), torch.from_numpy(data['test'].labels)\n",
    "\n",
    "        # create datasets\n",
    "        train_data = TensorDataset(X_train, Y_train)\n",
    "        valid_data = TensorDataset(X_validation, Y_validation)\n",
    "        test_data = TensorDataset(X_test, Y_test)\n",
    "        return train_data, valid_data, test_data\n",
    "        \n",
    "    # Transforms to perform on loaded dataset. Normalize around mean 0.1307 and std 0.3081 for optimal pytorch results. \n",
    "    # source: https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457/4\n",
    "    transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.1307,),(0.3081,))])\n",
    "\n",
    "    # Load datasets into reproduction/data/mnist\n",
    "    mnist_train = DataLoader(torchvision.datasets.MNIST(os.path.join(data_folder, \"mnist_original\"), train=True, download=True, transform=transforms))\n",
    "    mnist_test = DataLoader(torchvision.datasets.MNIST(os.path.join(data_folder, \"mnist_original\"), train=False, download=True, \n",
    "                                                       transform=transforms))\n",
    "        \n",
    "    mnist_train_data = mnist_train.dataset.data\n",
    "    mnist_train_targets = mnist_train.dataset.targets\n",
    "    \n",
    "    x_test = mnist_test.dataset.data\n",
    "    y_test = mnist_test.dataset.targets\n",
    "    \n",
    "    if data_flag == \"mnist_original\":\n",
    "        x_train = mnist_train_data[0:55000]\n",
    "        y_train = mnist_train_targets[0:55000]\n",
    "\n",
    "        x_valid = mnist_train_data[55000:60000]\n",
    "        y_valid = mnist_train_targets[55000:60000]\n",
    "        \n",
    "        train_data = TensorDataset(x_train, y_train)\n",
    "        valid_data = TensorDataset(x_valid, y_valid)\n",
    "        test_data = TensorDataset(x_test, y_test)\n",
    "        \n",
    "        return train_data, valid_data, test_data\n",
    "\n",
    "    to_gray = (data_flag == \"mnist_rgb2gray\")\n",
    "    x_train_color = color_dataset(mnist_train_data, to_gray)\n",
    "    x_test_color = color_dataset(x_test, to_gray)\n",
    "\n",
    "    # ADDED THIS\n",
    "    mnist_train = TensorDataset(x_train_color, mnist_train_targets)\n",
    "    mnist_test = TensorDataset(x_test_color, y_test)\n",
    "\n",
    "    # first 55000 examples for training\n",
    "    x_train = mnist_train[0:55000][0]\n",
    "    y_train = mnist_train[0:55000][1]\n",
    "    # y_train = mnist_train_targets[0:55000]\n",
    "\n",
    "    # 5000 examples for validation set\n",
    "    x_valid = mnist_train[55000:60000][0]\n",
    "    y_valid = mnist_train[55000:60000][1]\n",
    "\n",
    "    # 10000 examples in test set\n",
    "    x_test = mnist_test[:][0]\n",
    "    y_test = mnist_test[:][1]\n",
    "\n",
    "    train_data = TensorDataset(x_train, y_train)\n",
    "    valid_data = TensorDataset(x_valid, y_valid)\n",
    "    test_data = TensorDataset(x_test, y_test)\n",
    "    \n",
    "    return train_data, valid_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cw463kVp3CeL"
   },
   "outputs": [],
   "source": [
    "if WHICH_DATA_FLAG == \"mnist_color\":\n",
    "    with open(\"./data/github_data/mnist_color28/MNIST_color28_train.p\", \"rb\") as f:\n",
    "        mnist_train = pickle.load(f)\n",
    "\n",
    "    with open(\"./data/github_data/mnist_color28/MNIST_color28_test.p\", \"rb\") as f:\n",
    "        mnist_test = pickle.load(f)\n",
    "    \n",
    "    # first 55000 examples for training\n",
    "    x_train = mnist_train[0:55000][0]\n",
    "    y_train = mnist_train[0:55000][1]\n",
    "    # y_train = mnist_train_targets[0:55000]\n",
    "\n",
    "    # 5000 examples for validation set\n",
    "    x_valid = mnist_train[55000:60000][0]\n",
    "    y_valid = mnist_train[55000:60000][1]\n",
    "\n",
    "    # 10000 examples in test set\n",
    "    x_test = mnist_test[:][0]\n",
    "    y_test = mnist_test[:][1]\n",
    "\n",
    "    train_data = TensorDataset(x_train, y_train)\n",
    "    valid_data = TensorDataset(x_valid, y_valid)\n",
    "    test_data = TensorDataset(x_test, y_test)\n",
    "    \n",
    "elif WHICH_DATA_FLAG == \"mnist_rgb2gray\": \n",
    "    with open(\"./data/github_data/mnist_color28_gray/MNIST_color28_gray_train.p\", \"rb\") as f:\n",
    "        mnist_train = pickle.load(f)\n",
    "\n",
    "    with open(\"./data/github_data/mnist_color28_gray/MNIST_color28_gray_test.p\", \"rb\") as f:\n",
    "        mnist_test = pickle.load(f)\n",
    "    \n",
    "    # first 55000 examples for training\n",
    "    x_train = mnist_train[0:55000][0]\n",
    "    y_train = mnist_train[0:55000][1]\n",
    "    # y_train = mnist_train_targets[0:55000]\n",
    "\n",
    "    # 5000 examples for validation set\n",
    "    x_valid = mnist_train[55000:60000][0]\n",
    "    y_valid = mnist_train[55000:60000][1]\n",
    "\n",
    "    # 10000 examples in test set\n",
    "    x_test = mnist_test[:][0]\n",
    "    y_test = mnist_test[:][1]\n",
    "\n",
    "    train_data = TensorDataset(x_train, y_train)\n",
    "    valid_data = TensorDataset(x_valid, y_valid)\n",
    "    test_data = TensorDataset(x_test, y_test)\n",
    "    \n",
    "elif WHICH_DATA_FLAG == \"mnist_original\":\n",
    "    mnist_train = torchvision.datasets.MNIST(\"./data/github_data/mnist/\", train=True, download=False)\n",
    "    mnist_test = torchvision.datasets.MNIST(\"./data/github_data/mnist/\", train=False, download=False)\n",
    "        \n",
    "    mnist_train = DataLoader(mnist_train)\n",
    "    mnist_test = DataLoader(mnist_test)\n",
    "    \n",
    "    mnist_train_data = mnist_train.dataset.data\n",
    "    mnist_train_targets = mnist_train.dataset.targets\n",
    "                  \n",
    "    x_test = mnist_test.dataset.data\n",
    "    y_test = mnist_test.dataset.targets\n",
    "    \n",
    "    x_train = mnist_train_data[0:55000]\n",
    "    y_train = mnist_train_targets[0:55000]\n",
    "\n",
    "    x_valid = mnist_train_data[55000:60000]\n",
    "    y_valid = mnist_train_targets[55000:60000]\n",
    "\n",
    "    train_data = TensorDataset(x_train, y_train)\n",
    "    valid_data = TensorDataset(x_valid, y_valid)\n",
    "    test_data = TensorDataset(x_test, y_test)\n",
    "              \n",
    "elif WHICH_DATA_FLAG == \"cifar\":\n",
    "    # extract cifar data\n",
    "#     !sh ./data/github_data/cifar-10-batches-py/\n",
    "    data = get_cifar10('./data/github_data/cifar-10-batches-py/', one_hot=False)\n",
    "\n",
    "    # extract training,validation and test data\n",
    "    X_train, Y_train = torch.from_numpy(data['train'].images), torch.from_numpy(data['train'].labels)\n",
    "    X_validation, Y_validation = torch.from_numpy(data['validation'].images), torch.from_numpy(data['validation'].labels)\n",
    "    X_test, Y_test = torch.from_numpy(data['test'].images), torch.from_numpy(data['test'].labels)\n",
    "\n",
    "    # create datasets\n",
    "    train_data = TensorDataset(X_train, Y_train)\n",
    "    valid_data = TensorDataset(X_validation, Y_validation)\n",
    "    test_data = TensorDataset(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "odhlqUB1uSuK"
   },
   "source": [
    "## Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "obnW_fswuSuK"
   },
   "outputs": [],
   "source": [
    "# COPIED FROM THE ORIGINAL IMPLEMENTATION\n",
    "# training parameters\n",
    "learning_rate = 0.002\n",
    "training_epochs = 35\n",
    "\n",
    "# frequency of testing and saving\n",
    "test_display_step = 5    # how many epochs we do evaluate on the test set once, default 100\n",
    "save_step = 50            # how frequently do we save the model to disk\n",
    "\n",
    "# elastic deformation parameters\n",
    "sigma = 4\n",
    "alpha = 20\n",
    "\n",
    "# lambda's are the ratios between the four error terms\n",
    "lambda_class = 20\n",
    "lambda_ae = 1 # autoencoder\n",
    "lambda_1 = 1 # push prototype vectors to have meaningful decodings in pixel space\n",
    "lambda_2 = 1 # cluster training examples around prototypes in latent space\n",
    "\n",
    "input_height = input_width = image_size   # either 28 or 32\n",
    "input_size = input_height * input_width * n_input_channels   # 784\n",
    "n_classes = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_prototypes = 15         # the number of prototypes\n",
    "n_layers = 4\n",
    "\n",
    "# height and width of each layers' filters\n",
    "f_1 = 3\n",
    "f_2 = 3\n",
    "f_3 = 3\n",
    "f_4 = 3\n",
    "\n",
    "# stride size in each direction for each of the layers\n",
    "s_1 = 2\n",
    "s_2 = 2\n",
    "s_3 = 2\n",
    "s_4 = 2\n",
    "\n",
    "# number of feature maps in each layer\n",
    "n_map_1 = 32\n",
    "n_map_2 = 32\n",
    "n_map_3 = 32\n",
    "n_map_4 = 10\n",
    "\n",
    "# the shapes of each layer's filter\n",
    "# [out channel, in_channel, 3, 3]\n",
    "filter_shape_1 = [n_map_1, n_input_channels, f_1, f_1]\n",
    "filter_shape_2 = [n_map_2, n_map_1, f_2, f_2]\n",
    "filter_shape_3 = [n_map_3, n_map_2, f_3, f_3]\n",
    "filter_shape_4 = [n_map_4, n_map_3, f_4, f_4]\n",
    "\n",
    "# strides for each layer (changed to tuples)\n",
    "stride_1 = [s_1, s_1]\n",
    "stride_2 = [s_2, s_2]\n",
    "stride_3 = [s_3, s_3]\n",
    "stride_4 = [s_4, s_4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Og1vbqkuSuO"
   },
   "source": [
    "## Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MPxGJI_GuSuP"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    '''Encoder'''\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # height and width of each layers' filters\n",
    "        f_1 = 3\n",
    "        f_2 = 3\n",
    "        f_3 = 3\n",
    "        f_4 = 3\n",
    "        \n",
    "        # define layers\n",
    "        self.enc_l1 = nn.Conv2d(n_input_channels, 32, kernel_size=3, stride=2, padding=0)\n",
    "        self.enc_l2 = nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=0)\n",
    "        self.enc_l3 = nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=0)\n",
    "        self.enc_l4 = nn.Conv2d(32, 10, kernel_size=3, stride=2, padding=0)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def pad_image(self, img):\n",
    "        ''' Takes an input image (batch) and pads according to Tensorflows SAME padding'''\n",
    "        input_h = img.shape[2]\n",
    "        input_w = img.shape[3]\n",
    "        stride = 2 \n",
    "        filter_h = 3\n",
    "        filter_w = 3\n",
    "\n",
    "        output_h = int(ceil(float(input_h)) / float(stride))\n",
    "        output_w = output_h\n",
    "\n",
    "        if input_h % stride == 0:\n",
    "            pad_height = max((filter_h - stride), 0)\n",
    "        else:\n",
    "            pad_height = max((filter_h - (input_h % stride), 0))\n",
    "\n",
    "        pad_width = pad_height\n",
    "\n",
    "        pad_top = pad_height // 2\n",
    "        pad_bottom = pad_height - pad_top\n",
    "        pad_left = pad_width // 2\n",
    "        pad_right = pad_width - pad_left\n",
    "\n",
    "        padded_img = torch.zeros(img.shape[0], img.shape[1], input_h + pad_height, input_w + pad_width)\n",
    "        padded_img[:,:, pad_top:-pad_bottom, pad_left:-pad_right] = img\n",
    "\n",
    "        return padded_img\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pad_x = self.pad_image(x)\n",
    "        el1 = self.relu(self.enc_l1(pad_x))\n",
    "        \n",
    "        pad_el1 = self.pad_image(el1)\n",
    "        el2 = self.relu(self.enc_l2(pad_el1))\n",
    "    \n",
    "        pad_el2 = self.pad_image(el2)\n",
    "        el3 = self.relu(self.enc_l3(pad_el2))\n",
    "        \n",
    "        pad_el3 = self.pad_image(el3)\n",
    "        el4 = self.relu(self.enc_l4(pad_el3))\n",
    "        \n",
    "        return el4\n",
    "        \n",
    "class Decoder(nn.Module):\n",
    "    '''Decoder'''\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        # height and width of each layers' filters\n",
    "        f_1 = 3\n",
    "        f_2 = 3\n",
    "        f_3 = 3\n",
    "        f_4 = 3\n",
    "        \n",
    "        if image_size == 28:\n",
    "            padding_correction = 0\n",
    "        else:\n",
    "            padding_correction = 1\n",
    "\n",
    "        # define layers\n",
    "        self.dec_l4 = nn.ConvTranspose2d(10, 32, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.dec_l3 = nn.ConvTranspose2d(32, 32, kernel_size=3, stride=2, padding=1, output_padding=padding_correction)\n",
    "        self.dec_l2 = nn.ConvTranspose2d(32, 32, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.dec_l1 = nn.ConvTranspose2d(32, n_input_channels, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, enc_x):\n",
    "        dl4 = self.relu(self.dec_l4(enc_x))\n",
    "        dl3 = self.relu(self.dec_l3(dl4))\n",
    "        dl2 = self.relu(self.dec_l2(dl3))\n",
    "        decoded_x = self.sigmoid(self.dec_l1(dl2))\n",
    "        \n",
    "        return decoded_x\n",
    "\n",
    "\n",
    "class nn_prototype(nn.Module):\n",
    "    '''Model'''\n",
    "    def __init__(self, n_prototypes=15, n_layers=4, n_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "        \n",
    "        # initialize prototype - currently not in correct spot\n",
    "        \n",
    "        # changed this for the colored mnist, from 40 to 160, the new shape would be 250*10*4*4\n",
    "        n_features = 40 # size of encoded x - 250 x 10 x 2 x 2\n",
    "        self.prototype_feature_vectors = nn.Parameter(torch.empty(size=(n_prototypes, n_features), \n",
    "                                                                  dtype=torch.float32).uniform_())\n",
    "        \n",
    "        self.last_layer = nn.Linear(n_prototypes,10)\n",
    "        \n",
    "    def list_of_distances(self, X, Y):\n",
    "        '''\n",
    "        Given a list of vectors, X = [x_1, ..., x_n], and another list of vectors,\n",
    "        Y = [y_1, ... , y_m], we return a list of vectors\n",
    "                [[d(x_1, y_1), d(x_1, y_2), ... , d(x_1, y_m)],\n",
    "                 ...\n",
    "                 [d(x_n, y_1), d(x_n, y_2), ... , d(x_n, y_m)]],\n",
    "        where the distance metric used is the sqared euclidean distance.\n",
    "        The computation is achieved through a clever use of broadcasting.\n",
    "        '''\n",
    "        XX = torch.reshape(list_of_norms(X), shape=(-1, 1))\n",
    "        YY = torch.reshape(list_of_norms(Y), shape=(1, -1))\n",
    "        output = XX + YY - 2 * torch.mm(X, Y.t())\n",
    "\n",
    "        return output\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #print(\"Shape of input x\", x.shape)\n",
    "        \n",
    "        #encoder step\n",
    "        enc_x = self.encoder(x)\n",
    "        \n",
    "        #print(\"Shape of encoded x\", enc_x.shape)\n",
    "        \n",
    "        #decoder step\n",
    "        dec_x = self.decoder(enc_x)\n",
    "        \n",
    "        #print(\"shape of decoded x\", dec_x.shape)\n",
    "        \n",
    "        # flatten encoded x to compute distance with prototypes\n",
    "        n_features = enc_x.shape[1] * enc_x.shape[2] * enc_x.shape[3]\n",
    "        feature_vectors_flat = torch.reshape(enc_x, shape=[-1, n_features])\n",
    "        \n",
    "        #print(\"Shape of flattened feature vectors\", feature_vectors_flat.shape)\n",
    "        \n",
    "        # distance to prototype\n",
    "        prototype_distances = self.list_of_distances(feature_vectors_flat, self.prototype_feature_vectors)\n",
    "        \n",
    "        # distance to feature vectors\n",
    "        feature_vector_distances = self.list_of_distances(self.prototype_feature_vectors, feature_vectors_flat)\n",
    "        \n",
    "        # classification layer\n",
    "        logits = self.last_layer(prototype_distances)\n",
    "        \n",
    "        return dec_x, logits, feature_vector_distances, prototype_distances\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DayzEANwuSuT"
   },
   "source": [
    "## Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tB_v14sCuSuU"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "the error function consists of 4 terms, the autoencoder loss,\n",
    "the classification loss, and the two requirements that every feature vector in\n",
    "X look like at least one of the prototype feature vectors and every prototype\n",
    "feature vector look like at least one of the feature vectors in X.\n",
    "'''\n",
    "def loss_function(X_decoded, X_true, logits, Y, feature_dist, prototype_dist, lambdas=None, print_flag=False):\n",
    "    if lambdas == None:\n",
    "        lam_class, lam_ae, lam_1, lam_2 = lambda_class, lambda_ae, lambda_1, lambda_2\n",
    "    \n",
    "    ae_error = torch.mean(list_of_norms(X_decoded - X_true))\n",
    "#     ae_error = F.binary_cross_entropy(X_decoded, X_true)\n",
    "    class_error = F.cross_entropy(logits, Y, reduction=\"mean\")\n",
    "    error_1 = torch.mean(torch.min(feature_dist, axis=1)[0])\n",
    "    error_2 = torch.mean(torch.min(prototype_dist, axis = 1)[0])\n",
    "\n",
    "    # total_error is the our minimization objective\n",
    "    total_error = lam_class * class_error +\\\n",
    "                  lam_ae * ae_error + \\\n",
    "                  lam_1 * error_1 + \\\n",
    "                  lam_2 * error_2\n",
    "    \n",
    "    if print_flag == True:\n",
    "        print('classification error', class_error.item())\n",
    "        print('AE error: ', ae_error.item())\n",
    "        print('Error 1: %f and 2: %f' %(error_1.item(), error_2.item()))\n",
    "    return total_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S_cOzaKUuSuW"
   },
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f-A00n7muSuY"
   },
   "outputs": [],
   "source": [
    "def compute_acc(logits, labels):\n",
    "    batch_size = labels.shape[0]\n",
    "    predictions = logits.argmax(dim=1)\n",
    "    total_correct = torch.sum(predictions == labels).item()\n",
    "    accuracy = total_correct / batch_size\n",
    "    \n",
    "    return(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tad0SGmuuSub"
   },
   "source": [
    "## Function to visualize prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RxGadYNpuSuc"
   },
   "outputs": [],
   "source": [
    "def visualize_prototypes(model, epoch, save=True):\n",
    "    # get saved prototypes\n",
    "    encoded_prototypes = model.prototype_feature_vectors\n",
    "    encoded_prototypes_reshaped = encoded_prototypes.view(n_prototypes, 10, 2, 2)\n",
    "\n",
    "    # decode prototypes\n",
    "    decoded_prototypes = model.decoder(encoded_prototypes_reshaped).detach().numpy()\n",
    "    \n",
    "    dec_prot = decoded_prototypes.transpose(0, 2, 3, 1)\n",
    "\n",
    "    for i in range(n_prototypes):\n",
    "        plt.imshow(dec_prot[i].squeeze())\n",
    "        if save:\n",
    "            makedirs(img_folder+\"/prototypes_epoch_\"+ str(epoch))\n",
    "            plt.savefig(img_folder+\"/prototypes_epoch_\"+ str(epoch)+\"/\"+str(i)+\".png\")\n",
    "        else:\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZYhUIE8HuSuf"
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "aQ0USgAeuSug",
    "outputId": "22473ed3-2f6f-4d6a-d67b-b3e48440f1e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5861ef8c6748>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# backpropagate over the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# update the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/berend/miniconda3/envs/fact/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/berend/miniconda3/envs/fact/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = nn_prototype(15,4,10)\n",
    "\n",
    "# get validation and test set\n",
    "valid_dl = DataLoader(valid_data, batch_size=5000, drop_last=False, shuffle=False)\n",
    "test_dl = DataLoader(test_data, batch_size=10000, drop_last=False, shuffle=False)\n",
    "\n",
    "# initialize optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# initialize storage for results\n",
    "train_accs = []\n",
    "train_losses = []\n",
    "test_accs = []\n",
    "test_losses = []\n",
    "valid_accs = []\n",
    "valid_losses = []\n",
    "\n",
    "# training loop\n",
    "for epoch in range(training_epochs):\n",
    "    print(\"\\nEpoch:\", epoch)\n",
    "\n",
    "    # load the training data and reshuffle\n",
    "    train_dl = DataLoader(train_data, batch_size=batch_size, drop_last=False, shuffle=True)\n",
    "    \n",
    "    # loop over the batches\n",
    "    model.train()\n",
    "    for step, (x, Y) in enumerate(train_dl):    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # this can be used to visualize the performance of the decoder\n",
    "        #x_plot = x[0].clone()\n",
    "        \n",
    "        if WHICH_DATA_FLAG == \"mnist_original\" or WHICH_DATA_FLAG == \"mnist_color\":\n",
    "            x = x.view(x.shape[0], n_input_channels, x.shape[1], x.shape[2]).float() /255\n",
    "        elif WHICH_DATA_FLAG == \"cifar\":\n",
    "            x = x / 255\n",
    "        else:\n",
    "            x = x.view(x.shape[0], n_input_channels, x.shape[1], x.shape[2]).float()\n",
    "\n",
    "        Y = Y.long()\n",
    "        \n",
    "        # perform forward pass\n",
    "        X_decoded, logits, feature_dist, prot_dist = model(x)\n",
    "\n",
    "        # compute the loss\n",
    "        total_loss = loss_function(X_decoded, x, logits, Y, feature_dist, prot_dist)\n",
    "\n",
    "        # backpropagate over the loss\n",
    "        total_loss.backward()\n",
    "\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # compute and save accuracy and loss\n",
    "        train_accuracy = compute_acc(logits, Y)\n",
    "        train_accs.append(train_accuracy)\n",
    "        train_losses.append(total_loss.item())\n",
    "    \n",
    "    # uncomment x_plot defition above and the 4 lines below to check decoder performance\n",
    "    # encode one training example to check:\n",
    "#     plt.imshow(x_plot)\n",
    "#     plt.show()\n",
    "#     plt.imshow(X_decoded[0].detach().view(28, 28, 3))\n",
    "#     plt.show()\n",
    "\n",
    "    # print information after a batch\n",
    "    print('Last train loss of batch:', total_loss.item())\n",
    "    print('Train acc on batch:', np.mean(train_accs[-step:]))\n",
    "    print(\"Last train acc\", train_accuracy)\n",
    "\n",
    "    model.eval()\n",
    "    if epoch % test_display_step == 0:\n",
    "#         Uncomment line below to save model and prototypes\n",
    "#         torch.save(model, model_folder + \"/\" + model_filename + \"_epoch_\" + str(epoch) + '.pt')\n",
    "  \n",
    "#         Uncomment lines below to save model prototypes\n",
    "#         visualize_prototypes(model, epoch, save = True)\n",
    "#         print(\"Model and prototypes of epoch %d are saved\"%epoch)\n",
    "        \n",
    "#         perform testing\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "        for (x_test, y_test) in test_dl:\n",
    "            if WHICH_DATA_FLAG == \"mnist_original\" or WHICH_DATA_FLAG == \"mnist_color\":\n",
    "                x_test = x_test.view(x_test.shape[0], n_input_channels, x_test.shape[1], x_test.shape[2]).float() / 255\n",
    "            elif WHICH_DATA_FLAG == \"cifar\":\n",
    "                x_test = x_test / 255\n",
    "            else:\n",
    "                x_test = x_test.view(x_test.shape[0], n_input_channels, x_test.shape[1], x_test.shape[2]).float()\n",
    "            #y_test = y_test.long()\n",
    "\n",
    "            # forward pass\n",
    "            X_decoded, logits, feature_dist, prot_dist = model(x_test)\n",
    "\n",
    "            # compute loss and accuracy and save\n",
    "            test_accuracy = compute_acc(logits, y_test)\n",
    "            test_loss = loss_function(X_decoded, x_test, logits, y_test, feature_dist, prot_dist)\n",
    "            test_accs.append(test_accuracy)\n",
    "            test_losses.append(test_loss)\n",
    "\n",
    "        print('\\nTest loss:', test_loss.item())\n",
    "        print('Test acc:', test_accuracy)\n",
    "\n",
    "    # validation\n",
    "    for (x_valid, y_valid) in valid_dl:\n",
    "        if WHICH_DATA_FLAG == \"mnist_original\" or WHICH_DATA_FLAG == \"mnist_color\":\n",
    "            x_valid = x_valid.view(x_valid.shape[0], n_input_channels, x_valid.shape[1], x_valid.shape[2]).float() / 255\n",
    "        elif WHICH_DATA_FLAG == \"cifar\":\n",
    "            x_valid = x_valid / 255\n",
    "        else:\n",
    "            x_valid = x_valid.view(x_valid.shape[0], n_input_channels, x_valid.shape[1], x_valid.shape[2]).float()\n",
    "        X_decoded, logits, feature_dist, prot_dist = model(x_valid)\n",
    "\n",
    "        # compute losses and accuracy and save\n",
    "        valid_accuracy = compute_acc(logits, y_valid)\n",
    "        valid_loss = loss_function(X_decoded, x_valid, logits, y_valid, feature_dist, prot_dist, print_flag=False)\n",
    "        valid_accs.append(valid_accuracy)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "    print('\\nValid loss:', valid_loss.item())\n",
    "    print('Valid acc:', valid_accuracy)\n",
    "\n",
    "\n",
    "# # Uncomment to save results\n",
    "# metrics_folder = os.path.join(model_folder, \"metrics\")\n",
    "\n",
    "# with open(metrics_folder + '/train_accs.p', 'wb') as f:\n",
    "#     pickle.dump(train_accs, f)\n",
    "\n",
    "# with open(metrics_folder + '/test_accs.p', 'wb') as f:\n",
    "#     pickle.dump(test_accs, f)\n",
    "\n",
    "# with open(metrics_folder + '/valid_accs.p', 'wb') as f:\n",
    "#     pickle.dump(valid_accs, f)\n",
    "\n",
    "# with open(metrics_folder + '/train_losses.p', 'wb') as f:a\n",
    "#     pickle.dump(train_losses, f)\n",
    "\n",
    "# with open(metrics_folder + '/test_losses.p', 'wb') as f:\n",
    "#     pickle.dump(test_losses, f)\n",
    "\n",
    "# with open(metrics_folder + '/valid_losses.p', 'wb') as f:\n",
    "#     pickle.dump(valid_losses, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YodtsalAuSul"
   },
   "source": [
    "# Reporting results\n",
    "When performing the grid search on Surfsara, all models and their scores have been saved in model folders. The code below will load the test accuracies for every model to determine at which epoch the model scored best. In turn, it will load the model at the respective epoch and perform the classification task on the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting standard model, cifar model, grid search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R_6q4_teuSuo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Reproduction/saved_model/mnist_model/\n",
      "Test acc: 0.9908\n",
      "Saved test acc: 0.9908\n"
     ]
    }
   ],
   "source": [
    "if WHICH_DATA_FLAG == \"mnist_color\":\n",
    "    search_path = glob.glob(\"./saved_model/mnist_model_color28*\")\n",
    "if WHICH_DATA_FLAG == \"mnist_rgb2gray\":\n",
    "    search_path = glob.glob(\"./saved_model/gray*\")\n",
    "if WHICH_DATA_FLAG == \"cifar\":\n",
    "    search_path = glob.glob(\"./saved_model/cifar_model/\")\n",
    "elif WHICH_DATA_FLAG == \"mnist_original\":\n",
    "    search_path = glob.glob(\"./saved_model/mnist_model/\")\n",
    "    \n",
    "test_dl = DataLoader(test_data, batch_size=10000, drop_last=False, shuffle=False)\n",
    "    \n",
    "for folder in search_path:\n",
    "    \n",
    "    # Check the find accs file for best epoch\n",
    "    accsfile = folder + '/metrics/test_accs.p'\n",
    "    with open(accsfile, 'rb') as f:\n",
    "        test_accs = pickle.load(f)\n",
    "    max_epoch = np.argmax(test_accs) * 5\n",
    "    \n",
    "    # define best model path\n",
    "    best_model = glob.glob(folder + '/*' + str(max_epoch) + '.pt')[0]\n",
    "#     print(best_model)\n",
    "    # load model ## check map_location, maybe if statement cuda is available??\n",
    "    loaded_model = torch.load(best_model,  map_location=torch.device('cpu'))\n",
    "    \n",
    "    loaded_model.eval()\n",
    "    for (x_test, y_test) in test_dl:\n",
    "        if WHICH_DATA_FLAG == \"mnist_original\" or WHICH_DATA_FLAG == \"mnist_color\":\n",
    "            x_test = x_test.view(x_test.shape[0], n_input_channels, x_test.shape[1], x_test.shape[2]).float() / 255\n",
    "        elif WHICH_DATA_FLAG == \"cifar\":\n",
    "            x_test = x_test / 255\n",
    "        else:\n",
    "            x_test = x_test.view(x_test.shape[0], n_input_channels, x_test.shape[1], x_test.shape[2]).float()\n",
    "        #y_test = y_test.long()\n",
    "\n",
    "        # forward pass\n",
    "        X_decoded, logits, feature_dist, prot_dist = loaded_model(x_test)\n",
    "\n",
    "        # compute loss and accuracy and save\n",
    "        test_accuracy = compute_acc(logits, y_test)\n",
    "        test_loss = loss_function(X_decoded, x_test, logits, y_test, feature_dist, prot_dist)\n",
    "\n",
    "#     print('\\nTest loss:', test_loss.item())\n",
    "    print(folder)\n",
    "    print('Test acc:', test_accuracy)\n",
    "    print('Saved test acc:', max(test_accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_jShibheuSuq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hs81YdnVuSus"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-vYtGp0fuSuw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tHoM3jTFuSux"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Final_notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
