{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xyqdJDGiuStN"
   },
   "source": [
    "# Complete notebook with code to generate all the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sc1wRCCLuStS"
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from math import ceil\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import pickle \n",
    "import scipy.ndimage\n",
    "from PIL import Image as PILImage\n",
    "from skimage.color import rgb2gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LhBVEiXquSta"
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5sXJOMTuStc"
   },
   "outputs": [],
   "source": [
    "# borrowed from the original paper of Li et al. (2018)\n",
    "def makedirs(path):\n",
    "    '''\n",
    "    if path does not exist in the file system, create it\n",
    "    '''\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def list_of_norms(X):\n",
    "    '''\n",
    "    X is a list of vectors X = [x_1, ..., x_n], we return\n",
    "        [d(x_1, x_1), d(x_2, x_2), ... , d(x_n, x_n)], where the distance\n",
    "    function is the squared euclidean distance.\n",
    "    '''\n",
    "    return torch.sum(torch.pow(X, 2), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ESm8gfRQuSti"
   },
   "source": [
    "## Create necessary directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "33TgrqgcuStj"
   },
   "outputs": [],
   "source": [
    "# data folder\n",
    "data_folder = os.path.join(os.getcwd(), \"data\")\n",
    "makedirs(data_folder)\n",
    "\n",
    "# Various model folders\n",
    "model_original = os.path.join(os.getcwd(), \"models\", \"mnist_original\")\n",
    "model_cifar = os.path.join(os.getcwd(), \"models\", \"cifar\")\n",
    "model_mnist_color = os.path.join(os.getcwd(), \"models\", \"mnist_color\")\n",
    "model_mnist_rgb2gray = os.path.join(os.getcwd(), \"models\", \"mnist_rgb2gray\")\n",
    "\n",
    "model_folders_list = [model_original, model_cifar, model_mnist_color, model_mnist_rgb2gray]\n",
    "\n",
    "# Image folder in every model folder\n",
    "for model_folder in model_folders_list:\n",
    "    makedirs(os.path.join(model_folder, \"img\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xVCUJ_XiuSto"
   },
   "source": [
    "## Choose the dataset here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eKoKOBNQuStq"
   },
   "outputs": [],
   "source": [
    "# uncomment one of the assignments below\n",
    "# WHICH_DATA_FLAG = \"mnist_original\"\n",
    "#WHICH_DATA_FLAG = \"cifar\"\n",
    "WHICH_DATA_FLAG = \"mnist_color\"\n",
    "# WHICH_DATA_FLAG = \"mnist_rgb2gray\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5fE4zTqyuStu"
   },
   "source": [
    "## Parameters dependent on dataset, no input needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oLk4PIj5uStv"
   },
   "outputs": [],
   "source": [
    "batch_size = 250\n",
    "n_input_channels = 3 ** int(WHICH_DATA_FLAG==\"cifar\")\n",
    "image_size = 28\n",
    "if WHICH_DATA_FLAG == \"mnist_original\":\n",
    "    model_folder = model_original\n",
    "    model_filename = \"mnist_original\"\n",
    "elif WHICH_DATA_FLAG == \"mnist_color\":\n",
    "    model_folder = model_mnist_color\n",
    "    model_filename = \"mnist_color\"\n",
    "    n_input_channels = 3\n",
    "elif WHICH_DATA_FLAG == \"mnist_rgb2gray\":\n",
    "    model_folder = model_mnist_rgb2gray\n",
    "    model_filename = \"mnist_rgb2gray\"\n",
    "elif WHICH_DATA_FLAG == \"cifar\":\n",
    "    model_folder = model_cifar\n",
    "    model_filename = \"cifar\"\n",
    "    n_input_channels = 3\n",
    "    image_size = 32\n",
    "\n",
    "img_folder = os.path.join(model_folder, \"img\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szlpORCJuSt6"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "onRgMG-ruSt7"
   },
   "source": [
    "## Function to transform original MNIST to colored MNIST or rgb2gray MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-W-Ia3BMuSt8"
   },
   "outputs": [],
   "source": [
    "def color_dataset(raw_data, to_gray=False):\n",
    "    N = len(raw_data)\n",
    "    if to_gray:\n",
    "        n_channels = 1\n",
    "    else:\n",
    "        n_channels = 3\n",
    "    \n",
    "    raw_data = raw_data.view(N, 28, 28, 1)\n",
    "    \n",
    "    try:\n",
    "        lena = PILImage.open('./resources/lena.png')    \n",
    "    except:\n",
    "        print(\"Lena image could not be found, please check ./resources/lena.png\")\n",
    "        return 1\n",
    "            \n",
    "\n",
    "    # Extend to RGB\n",
    "    data_rgb = np.concatenate([raw_data, raw_data, raw_data], axis=3)\n",
    "    \n",
    "    # Make binary\n",
    "    data_binary = (data_rgb > 0.5)\n",
    "    data_color = np.zeros((N, 28, 28, n_channels))\n",
    "    \n",
    "    for i in range(N):\n",
    "        # Take a random crop of the Lena image (background)\n",
    "        x_c = np.random.randint(0, lena.size[0] - 28)\n",
    "        y_c = np.random.randint(0, lena.size[1] - 28)\n",
    "        image = lena.crop((x_c, y_c, x_c + 28, y_c + 28))\n",
    "        image = np.asarray(image) # / 255.0 REMOVED DIVISION HERE TO MAKE EVERY DATASET EQUAL\n",
    "\n",
    "        ## COPIED IMAGE BECAUSE \"READ-ONLY\" ERROR\n",
    "        new_image = image.copy()\n",
    "        # Change color distribution # SHOULD THIS ONLY HAPPEN IF TO_GRAY == FALSE?\n",
    "        for j in range(3):\n",
    "            new_image[:, :, j] = (new_image[:, :, j] + np.random.uniform(0, 1)) / 2.0\n",
    "\n",
    "        # Invert the colors at the location of the number\n",
    "        new_image[data_binary[i]] = 1 - new_image[data_binary[i]]\n",
    "        if to_gray:\n",
    "            data_color[i] = np.reshape(rgb2gray(new_image), (28, 28, 1))\n",
    "        else:\n",
    "            data_color[i] = new_image\n",
    "        \n",
    "    return torch.from_numpy(data_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "37FYDtEduSuA"
   },
   "source": [
    "## Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IbJd3XkmuSuB"
   },
   "outputs": [],
   "source": [
    "def get_data(data_flag):\n",
    "    # check if flag is correct\n",
    "    assert data_flag in [\"mnist_original\", \"cifar\", \"mnist_color\", \"mnist_rgb2gray\"]\n",
    "    \n",
    "    if data_flag == \"cifar\":\n",
    "        # extract cifar data\n",
    "        data = get_cifar10(os.path.join(data_folder, \"cifar\"), one_hot=False)\n",
    "\n",
    "        # extract training,validation and test data\n",
    "        X_train, Y_train = torch.from_numpy(data['train'].images), torch.from_numpy(data['train'].labels)\n",
    "        X_validation, Y_validation = torch.from_numpy(data['validation'].images), torch.from_numpy(data['validation'].labels)\n",
    "        X_test, Y_test = torch.from_numpy(data['test'].images), torch.from_numpy(data['test'].labels)\n",
    "\n",
    "        # create datasets\n",
    "        train_data = TensorDataset(X_train, Y_train)\n",
    "        valid_data = TensorDataset(X_validation, Y_validation)\n",
    "        test_data = TensorDataset(X_test, Y_test)\n",
    "        return train_data, valid_data, test_data\n",
    "        \n",
    "    # Transforms to perform on loaded dataset. Normalize around mean 0.1307 and std 0.3081 for optimal pytorch results. \n",
    "    # source: https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457/4\n",
    "    transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.1307,),(0.3081,))])\n",
    "\n",
    "    # Load datasets into reproduction/data/mnist\n",
    "    mnist_train = DataLoader(torchvision.datasets.MNIST(os.path.join(data_folder, \"mnist_original\"), train=True, download=True, transform=transforms))\n",
    "    mnist_test = DataLoader(torchvision.datasets.MNIST(os.path.join(data_folder, \"mnist_original\"), train=False, download=True, \n",
    "                                                       transform=transforms))\n",
    "        \n",
    "    mnist_train_data = mnist_train.dataset.data\n",
    "    mnist_train_targets = mnist_train.dataset.targets\n",
    "    \n",
    "    x_test = mnist_test.dataset.data\n",
    "    y_test = mnist_test.dataset.targets\n",
    "    \n",
    "    if data_flag == \"mnist_original\":\n",
    "        x_train = mnist_train_data[0:55000]\n",
    "        y_train = mnist_train_targets[0:55000]\n",
    "\n",
    "        x_valid = mnist_train_data[55000:60000]\n",
    "        y_valid = mnist_train_targets[55000:60000]\n",
    "        \n",
    "        train_data = TensorDataset(x_train, y_train)\n",
    "        valid_data = TensorDataset(x_valid, y_valid)\n",
    "        test_data = TensorDataset(x_test, y_test)\n",
    "        \n",
    "        return train_data, valid_data, test_data\n",
    "\n",
    "    to_gray = (data_flag == \"mnist_rgb2gray\")\n",
    "    x_train_color = color_dataset(mnist_train_data, to_gray)\n",
    "    x_test_color = color_dataset(x_test, to_gray)\n",
    "\n",
    "    # ADDED THIS\n",
    "    mnist_train = TensorDataset(x_train_color, mnist_train_targets)\n",
    "    mnist_test = TensorDataset(x_test_color, y_test)\n",
    "\n",
    "    # first 55000 examples for training\n",
    "    x_train = mnist_train[0:55000][0]\n",
    "    y_train = mnist_train[0:55000][1]\n",
    "    # y_train = mnist_train_targets[0:55000]\n",
    "\n",
    "    # 5000 examples for validation set\n",
    "    x_valid = mnist_train[55000:60000][0]\n",
    "    y_valid = mnist_train[55000:60000][1]\n",
    "\n",
    "    # 10000 examples in test set\n",
    "    x_test = mnist_test[:][0]\n",
    "    y_test = mnist_test[:][1]\n",
    "\n",
    "    train_data = TensorDataset(x_train, y_train)\n",
    "    valid_data = TensorDataset(x_valid, y_valid)\n",
    "    test_data = TensorDataset(x_test, y_test)\n",
    "    \n",
    "    return train_data, valid_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "968klvOGuSuG"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = get_data(WHICH_DATA_FLAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cw463kVp3CeL"
   },
   "outputs": [],
   "source": [
    "# plt.imshow(train_data[4][0].detach().numpy().reshape(32, 32, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "odhlqUB1uSuK"
   },
   "source": [
    "## Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "obnW_fswuSuK"
   },
   "outputs": [],
   "source": [
    "# COPIED FROM THE ORIGINAL IMPLEMENTATION\n",
    "# training parameters\n",
    "learning_rate = 0.002\n",
    "training_epochs = 1500\n",
    "\n",
    "# frequency of testing and saving\n",
    "test_display_step = 5    # how many epochs we do evaluate on the test set once, default 100\n",
    "save_step = 50            # how frequently do we save the model to disk\n",
    "\n",
    "# elastic deformation parameters\n",
    "sigma = 4\n",
    "alpha = 20\n",
    "\n",
    "# lambda's are the ratios between the four error terms\n",
    "lambda_class = 20\n",
    "lambda_ae = 1 # autoencoder\n",
    "lambda_1 = 1 # push prototype vectors to have meaningful decodings in pixel space\n",
    "lambda_2 = 1 # cluster training examples around prototypes in latent space\n",
    "\n",
    "\n",
    "input_height = input_width =  28    # MNIST data input shape \n",
    "n_input_channel = 3     # the number of color channels; for MNIST is 1.\n",
    "input_size = input_height * input_width * n_input_channel   # 784\n",
    "n_classes = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_prototypes = 15         # the number of prototypes\n",
    "n_layers = 4\n",
    "\n",
    "# height and width of each layers' filters\n",
    "f_1 = 3\n",
    "f_2 = 3\n",
    "f_3 = 3\n",
    "f_4 = 3\n",
    "\n",
    "# stride size in each direction for each of the layers\n",
    "s_1 = 2\n",
    "s_2 = 2\n",
    "s_3 = 2\n",
    "s_4 = 2\n",
    "\n",
    "# number of feature maps in each layer\n",
    "n_map_1 = 32\n",
    "n_map_2 = 32\n",
    "n_map_3 = 32\n",
    "n_map_4 = 10\n",
    "\n",
    "# the shapes of each layer's filter\n",
    "# [out channel, in_channel, 3, 3]\n",
    "filter_shape_1 = [n_map_1, n_input_channel, f_1, f_1]\n",
    "filter_shape_2 = [n_map_2, n_map_1, f_2, f_2]\n",
    "filter_shape_3 = [n_map_3, n_map_2, f_3, f_3]\n",
    "filter_shape_4 = [n_map_4, n_map_3, f_4, f_4]\n",
    "\n",
    "# strides for each layer (changed to tuples)\n",
    "stride_1 = [s_1, s_1]\n",
    "stride_2 = [s_2, s_2]\n",
    "stride_3 = [s_3, s_3]\n",
    "stride_4 = [s_4, s_4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Og1vbqkuSuO"
   },
   "source": [
    "## Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MPxGJI_GuSuP"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    '''Encoder'''\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # height and width of each layers' filters\n",
    "        f_1 = 3\n",
    "        f_2 = 3\n",
    "        f_3 = 3\n",
    "        f_4 = 3\n",
    "        \n",
    "        # define layers\n",
    "        self.enc_l1 = nn.Conv2d(n_input_channel, 32, kernel_size=3, stride=2, padding=0)\n",
    "        self.enc_l2 = nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=0)\n",
    "        self.enc_l3 = nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=0)\n",
    "        self.enc_l4 = nn.Conv2d(32, 10, kernel_size=3, stride=2, padding=0)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def pad_image(self, img):\n",
    "        ''' Takes an input image (batch) and pads according to Tensorflows SAME padding'''\n",
    "        input_h = img.shape[2]\n",
    "        input_w = img.shape[3]\n",
    "        stride = 2 \n",
    "        filter_h = 3\n",
    "        filter_w = 3\n",
    "\n",
    "        output_h = int(ceil(float(input_h)) / float(stride))\n",
    "        output_w = output_h\n",
    "\n",
    "        if input_h % stride == 0:\n",
    "            pad_height = max((filter_h - stride), 0)\n",
    "        else:\n",
    "            pad_height = max((filter_h - (input_h % stride), 0))\n",
    "\n",
    "        pad_width = pad_height\n",
    "\n",
    "        pad_top = pad_height // 2\n",
    "        pad_bottom = pad_height - pad_top\n",
    "        pad_left = pad_width // 2\n",
    "        pad_right = pad_width - pad_left\n",
    "\n",
    "        padded_img = torch.zeros(img.shape[0], img.shape[1], input_h + pad_height, input_w + pad_width)\n",
    "        padded_img[:,:, pad_top:-pad_bottom, pad_left:-pad_right] = img\n",
    "\n",
    "        return padded_img\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pad_x = self.pad_image(x)\n",
    "        el1 = self.relu(self.enc_l1(pad_x))\n",
    "        \n",
    "        pad_el1 = self.pad_image(el1)\n",
    "        el2 = self.relu(self.enc_l2(pad_el1))\n",
    "    \n",
    "        pad_el2 = self.pad_image(el2)\n",
    "        el3 = self.relu(self.enc_l3(pad_el2))\n",
    "        \n",
    "        pad_el3 = self.pad_image(el3)\n",
    "        el4 = self.relu(self.enc_l4(pad_el3))\n",
    "        \n",
    "        return el4\n",
    "        \n",
    "\n",
    "class nn_prototype(nn.Module):\n",
    "    '''Model'''\n",
    "    def __init__(self, n_prototypes=15, n_layers=4, n_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder()\n",
    "        \n",
    "        # initialize prototype - currently not in correct spot\n",
    "        \n",
    "        # changed this for the colored mnist, from 40 to 160, the new shape would be 250*10*4*4\n",
    "        n_features = 40 # size of encoded x - 250 x 10 x 2 x 2\n",
    "        self.prototype_replacement = nn.Linear(n_features, n_prototypes)\n",
    "        self.last_layer = nn.Linear(n_prototypes,10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "    \n",
    "        #encoder step\n",
    "        enc_x = self.encoder(x)\n",
    "        \n",
    "        x = enc_x.view(enc_x.shape[0], -1)\n",
    "    \n",
    "    \n",
    "        x = self.prototype_replacement(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # classification layer\n",
    "        logits = self.last_layer(x)\n",
    "        \n",
    "        # Softmax to prob dist not needed as cross entropy loss is used?\n",
    "        \n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DayzEANwuSuT"
   },
   "source": [
    "## Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tB_v14sCuSuU"
   },
   "outputs": [],
   "source": [
    "def loss_function(logits, Y):\n",
    "    return F.cross_entropy(logits, Y, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S_cOzaKUuSuW"
   },
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f-A00n7muSuY"
   },
   "outputs": [],
   "source": [
    "def compute_acc(logits, labels):\n",
    "    batch_size = labels.shape[0]\n",
    "    predictions = logits.argmax(dim=1)\n",
    "    total_correct = torch.sum(predictions == labels).item()\n",
    "    accuracy = total_correct / batch_size\n",
    "    \n",
    "    return(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZYhUIE8HuSuf"
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "aQ0USgAeuSug",
    "outputId": "22473ed3-2f6f-4d6a-d67b-b3e48440f1e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Last train loss of batch: 0.5150578022003174\n",
      "Train acc on batch: 0.6371141552511417\n",
      "Last train acc 0.84\n",
      "\n",
      "Test loss: 0.54306560754776\n",
      "Test acc: 0.833\n",
      "\n",
      "Valid loss: 0.4778297245502472\n",
      "Valid acc: 0.858\n",
      "\n",
      "Epoch: 1\n",
      "Last train loss of batch: 0.4095601439476013\n",
      "Train acc on batch: 0.8596712328767124\n",
      "Last train acc 0.864\n",
      "\n",
      "Valid loss: 0.32096049189567566\n",
      "Valid acc: 0.906\n",
      "\n",
      "Epoch: 2\n",
      "Last train loss of batch: 0.4034165143966675\n",
      "Train acc on batch: 0.8875433789954339\n",
      "Last train acc 0.856\n",
      "\n",
      "Valid loss: 0.2609080672264099\n",
      "Valid acc: 0.9242\n",
      "\n",
      "Epoch: 3\n",
      "Last train loss of batch: 0.2302708476781845\n",
      "Train acc on batch: 0.9042557077625573\n",
      "Last train acc 0.944\n",
      "\n",
      "Valid loss: 0.24607554078102112\n",
      "Valid acc: 0.9266\n",
      "\n",
      "Epoch: 4\n",
      "Last train loss of batch: 0.2083667367696762\n",
      "Train acc on batch: 0.9130776255707764\n",
      "Last train acc 0.936\n",
      "\n",
      "Valid loss: 0.21817559003829956\n",
      "Valid acc: 0.936\n",
      "\n",
      "Epoch: 5\n",
      "Last train loss of batch: 0.2639947235584259\n",
      "Train acc on batch: 0.9225936073059363\n",
      "Last train acc 0.92\n",
      "\n",
      "Test loss: 0.245710551738739\n",
      "Test acc: 0.925\n",
      "\n",
      "Valid loss: 0.2081298530101776\n",
      "Valid acc: 0.938\n",
      "\n",
      "Epoch: 6\n",
      "Last train loss of batch: 0.20300763845443726\n",
      "Train acc on batch: 0.9283105022831051\n",
      "Last train acc 0.948\n",
      "\n",
      "Valid loss: 0.23466423153877258\n",
      "Valid acc: 0.9318\n",
      "\n",
      "Epoch: 7\n",
      "Last train loss of batch: 0.20941567420959473\n",
      "Train acc on batch: 0.9329315068493151\n",
      "Last train acc 0.936\n",
      "\n",
      "Valid loss: 0.17349286377429962\n",
      "Valid acc: 0.9496\n",
      "\n",
      "Epoch: 8\n",
      "Last train loss of batch: 0.1702001690864563\n",
      "Train acc on batch: 0.9363835616438358\n",
      "Last train acc 0.936\n",
      "\n",
      "Valid loss: 0.17654278874397278\n",
      "Valid acc: 0.9484\n",
      "\n",
      "Epoch: 9\n",
      "Last train loss of batch: 0.17207106947898865\n",
      "Train acc on batch: 0.9424657534246574\n",
      "Last train acc 0.964\n",
      "\n",
      "Valid loss: 0.16222596168518066\n",
      "Valid acc: 0.9526\n",
      "\n",
      "Epoch: 10\n",
      "Last train loss of batch: 0.16036294400691986\n",
      "Train acc on batch: 0.944310502283105\n",
      "Last train acc 0.94\n",
      "\n",
      "Test loss: 0.24691501259803772\n",
      "Test acc: 0.9224\n",
      "\n",
      "Valid loss: 0.21203644573688507\n",
      "Valid acc: 0.9372\n",
      "\n",
      "Epoch: 11\n",
      "Last train loss of batch: 0.17108958959579468\n",
      "Train acc on batch: 0.9478538812785388\n",
      "Last train acc 0.94\n",
      "\n",
      "Valid loss: 0.16187433898448944\n",
      "Valid acc: 0.956\n",
      "\n",
      "Epoch: 12\n",
      "Last train loss of batch: 0.15229058265686035\n",
      "Train acc on batch: 0.9495707762557076\n",
      "Last train acc 0.96\n",
      "\n",
      "Valid loss: 0.15539179742336273\n",
      "Valid acc: 0.957\n",
      "\n",
      "Epoch: 13\n",
      "Last train loss of batch: 0.15356086194515228\n",
      "Train acc on batch: 0.9535890410958904\n",
      "Last train acc 0.94\n",
      "\n",
      "Valid loss: 0.14318908751010895\n",
      "Valid acc: 0.957\n",
      "\n",
      "Epoch: 14\n",
      "Last train loss of batch: 0.1801733672618866\n",
      "Train acc on batch: 0.9547031963470319\n",
      "Last train acc 0.948\n",
      "\n",
      "Valid loss: 0.14327365159988403\n",
      "Valid acc: 0.9588\n",
      "\n",
      "Epoch: 15\n",
      "Last train loss of batch: 0.1523929238319397\n",
      "Train acc on batch: 0.9577351598173515\n",
      "Last train acc 0.96\n",
      "\n",
      "Test loss: 0.1737254559993744\n",
      "Test acc: 0.9468\n",
      "\n",
      "Valid loss: 0.14463110268115997\n",
      "Valid acc: 0.9586\n",
      "\n",
      "Epoch: 16\n",
      "Last train loss of batch: 0.11627092212438583\n",
      "Train acc on batch: 0.9600365296803652\n",
      "Last train acc 0.956\n",
      "\n",
      "Valid loss: 0.15389150381088257\n",
      "Valid acc: 0.9536\n",
      "\n",
      "Epoch: 17\n",
      "Last train loss of batch: 0.19118408858776093\n",
      "Train acc on batch: 0.9606027397260275\n",
      "Last train acc 0.936\n",
      "\n",
      "Valid loss: 0.1597824990749359\n",
      "Valid acc: 0.9544\n",
      "\n",
      "Epoch: 18\n",
      "Last train loss of batch: 0.07979821413755417\n",
      "Train acc on batch: 0.9640547945205479\n",
      "Last train acc 0.976\n",
      "\n",
      "Valid loss: 0.13717074692249298\n",
      "Valid acc: 0.9616\n",
      "\n",
      "Epoch: 19\n",
      "Last train loss of batch: 0.10250990837812424\n",
      "Train acc on batch: 0.9641278538812785\n",
      "Last train acc 0.972\n",
      "\n",
      "Valid loss: 0.13633854687213898\n",
      "Valid acc: 0.9606\n",
      "\n",
      "Epoch: 20\n",
      "Last train loss of batch: 0.13784535229206085\n",
      "Train acc on batch: 0.9658447488584474\n",
      "Last train acc 0.944\n",
      "\n",
      "Test loss: 0.1662651002407074\n",
      "Test acc: 0.9517\n",
      "\n",
      "Valid loss: 0.13893987238407135\n",
      "Valid acc: 0.9628\n",
      "\n",
      "Epoch: 21\n",
      "Last train loss of batch: 0.1440889686346054\n",
      "Train acc on batch: 0.9676529680365297\n",
      "Last train acc 0.94\n",
      "\n",
      "Valid loss: 0.14430610835552216\n",
      "Valid acc: 0.9626\n",
      "\n",
      "Epoch: 22\n",
      "Last train loss of batch: 0.18415050208568573\n",
      "Train acc on batch: 0.969296803652968\n",
      "Last train acc 0.936\n",
      "\n",
      "Valid loss: 0.14256593585014343\n",
      "Valid acc: 0.9608\n",
      "\n",
      "Epoch: 23\n",
      "Last train loss of batch: 0.0677592009305954\n",
      "Train acc on batch: 0.9694794520547944\n",
      "Last train acc 0.984\n",
      "\n",
      "Valid loss: 0.14661045372486115\n",
      "Valid acc: 0.962\n",
      "\n",
      "Epoch: 24\n",
      "Last train loss of batch: 0.0776563361287117\n",
      "Train acc on batch: 0.9716347031963469\n",
      "Last train acc 0.972\n",
      "\n",
      "Valid loss: 0.13798169791698456\n",
      "Valid acc: 0.9634\n",
      "\n",
      "Epoch: 25\n",
      "Last train loss of batch: 0.12569661438465118\n",
      "Train acc on batch: 0.9734794520547946\n",
      "Last train acc 0.956\n",
      "\n",
      "Test loss: 0.17820996046066284\n",
      "Test acc: 0.9514\n",
      "\n",
      "Valid loss: 0.15742377936840057\n",
      "Valid acc: 0.9592\n",
      "\n",
      "Epoch: 26\n",
      "Last train loss of batch: 0.04507428780198097\n",
      "Train acc on batch: 0.9744840182648401\n",
      "Last train acc 0.992\n",
      "\n",
      "Valid loss: 0.1774141639471054\n",
      "Valid acc: 0.955\n",
      "\n",
      "Epoch: 27\n",
      "Last train loss of batch: 0.05542941018939018\n",
      "Train acc on batch: 0.9748310502283104\n",
      "Last train acc 0.976\n",
      "\n",
      "Valid loss: 0.1516214907169342\n",
      "Valid acc: 0.961\n",
      "\n",
      "Epoch: 28\n",
      "Last train loss of batch: 0.03711114823818207\n",
      "Train acc on batch: 0.9767488584474885\n",
      "Last train acc 0.984\n",
      "\n",
      "Valid loss: 0.15223440527915955\n",
      "Valid acc: 0.9616\n",
      "\n",
      "Epoch: 29\n",
      "Last train loss of batch: 0.06029434874653816\n",
      "Train acc on batch: 0.97786301369863\n",
      "Last train acc 0.984\n",
      "\n",
      "Valid loss: 0.15197135508060455\n",
      "Valid acc: 0.9644\n",
      "\n",
      "Epoch: 30\n",
      "Last train loss of batch: 0.0965590626001358\n",
      "Train acc on batch: 0.978593607305936\n",
      "Last train acc 0.972\n",
      "\n",
      "Test loss: 0.17932482063770294\n",
      "Test acc: 0.9529\n",
      "\n",
      "Valid loss: 0.16269536316394806\n",
      "Valid acc: 0.9626\n",
      "\n",
      "Epoch: 31\n",
      "Last train loss of batch: 0.06028743088245392\n",
      "Train acc on batch: 0.9786666666666667\n",
      "Last train acc 0.976\n",
      "\n",
      "Valid loss: 0.15063542127609253\n",
      "Valid acc: 0.964\n",
      "\n",
      "Epoch: 32\n",
      "Last train loss of batch: 0.051756199449300766\n",
      "Train acc on batch: 0.9802922374429223\n",
      "Last train acc 0.984\n",
      "\n",
      "Valid loss: 0.16520743072032928\n",
      "Valid acc: 0.9614\n",
      "\n",
      "Epoch: 33\n",
      "Last train loss of batch: 0.043858472257852554\n",
      "Train acc on batch: 0.980255707762557\n",
      "Last train acc 0.988\n",
      "\n",
      "Valid loss: 0.16263778507709503\n",
      "Valid acc: 0.9608\n",
      "\n",
      "Epoch: 34\n",
      "Last train loss of batch: 0.07784798741340637\n",
      "Train acc on batch: 0.9814246575342466\n",
      "Last train acc 0.976\n",
      "\n",
      "Valid loss: 0.1734676957130432\n",
      "Valid acc: 0.9626\n",
      "\n",
      "Epoch: 35\n",
      "Last train loss of batch: 0.08006201684474945\n",
      "Train acc on batch: 0.9828675799086756\n",
      "Last train acc 0.976\n",
      "\n",
      "Test loss: 0.20924484729766846\n",
      "Test acc: 0.9519\n",
      "\n",
      "Valid loss: 0.1661713719367981\n",
      "Valid acc: 0.9638\n",
      "\n",
      "Epoch: 36\n",
      "Last train loss of batch: 0.05274210125207901\n",
      "Train acc on batch: 0.9814429223744294\n",
      "Last train acc 0.98\n",
      "\n",
      "Valid loss: 0.20995056629180908\n",
      "Valid acc: 0.953\n",
      "\n",
      "Epoch: 37\n",
      "Last train loss of batch: 0.047902919352054596\n",
      "Train acc on batch: 0.9824109589041096\n",
      "Last train acc 0.984\n",
      "\n",
      "Valid loss: 0.16384918987751007\n",
      "Valid acc: 0.965\n",
      "\n",
      "Epoch: 38\n",
      "Last train loss of batch: 0.03644661605358124\n",
      "Train acc on batch: 0.9843470319634703\n",
      "Last train acc 0.988\n",
      "\n",
      "Valid loss: 0.1736573427915573\n",
      "Valid acc: 0.9634\n",
      "\n",
      "Epoch: 39\n",
      "Last train loss of batch: 0.12158844619989395\n",
      "Train acc on batch: 0.9845114155251141\n",
      "Last train acc 0.968\n",
      "\n",
      "Valid loss: 0.17594777047634125\n",
      "Valid acc: 0.9642\n",
      "\n",
      "Epoch: 40\n",
      "Last train loss of batch: 0.06632786989212036\n",
      "Train acc on batch: 0.9860091324200912\n",
      "Last train acc 0.976\n",
      "\n",
      "Test loss: 0.21642832458019257\n",
      "Test acc: 0.956\n",
      "\n",
      "Valid loss: 0.18068602681159973\n",
      "Valid acc: 0.9634\n",
      "\n",
      "Epoch: 41\n",
      "Last train loss of batch: 0.025732846930623055\n",
      "Train acc on batch: 0.9857351598173515\n",
      "Last train acc 0.992\n",
      "\n",
      "Valid loss: 0.17761710286140442\n",
      "Valid acc: 0.9648\n",
      "\n",
      "Epoch: 42\n",
      "Last train loss of batch: 0.05496395006775856\n",
      "Train acc on batch: 0.985972602739726\n",
      "Last train acc 0.98\n",
      "\n",
      "Valid loss: 0.2012386918067932\n",
      "Valid acc: 0.9554\n",
      "\n",
      "Epoch: 43\n",
      "Last train loss of batch: 0.052088700234889984\n",
      "Train acc on batch: 0.9849680365296803\n",
      "Last train acc 0.984\n",
      "\n",
      "Valid loss: 0.185674250125885\n",
      "Valid acc: 0.963\n",
      "\n",
      "Epoch: 44\n",
      "Last train loss of batch: 0.04197920113801956\n",
      "Train acc on batch: 0.9849132420091324\n",
      "Last train acc 0.984\n",
      "\n",
      "Valid loss: 0.1911078691482544\n",
      "Valid acc: 0.9592\n",
      "\n",
      "Epoch: 45\n",
      "Last train loss of batch: 0.057474590837955475\n",
      "Train acc on batch: 0.9877625570776255\n",
      "Last train acc 0.98\n",
      "\n",
      "Test loss: 0.21350105106830597\n",
      "Test acc: 0.9541\n",
      "\n",
      "Valid loss: 0.18811708688735962\n",
      "Valid acc: 0.9608\n",
      "\n",
      "Epoch: 46\n",
      "Last train loss of batch: 0.05072111263871193\n",
      "Train acc on batch: 0.9861004566210044\n",
      "Last train acc 0.972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valid loss: 0.2032422423362732\n",
      "Valid acc: 0.9592\n",
      "\n",
      "Epoch: 47\n",
      "Last train loss of batch: 0.048924822360277176\n",
      "Train acc on batch: 0.9868493150684932\n",
      "Last train acc 0.988\n",
      "\n",
      "Valid loss: 0.22010529041290283\n",
      "Valid acc: 0.9614\n",
      "\n",
      "Epoch: 48\n",
      "Last train loss of batch: 0.009270917624235153\n",
      "Train acc on batch: 0.9880730593607305\n",
      "Last train acc 1.0\n",
      "\n",
      "Valid loss: 0.1904541254043579\n",
      "Valid acc: 0.9664\n",
      "\n",
      "Epoch: 49\n",
      "Last train loss of batch: 0.014772309921681881\n",
      "Train acc on batch: 0.9890776255707763\n",
      "Last train acc 0.992\n",
      "\n",
      "Valid loss: 0.2025134116411209\n",
      "Valid acc: 0.9622\n",
      "\n",
      "Epoch: 50\n",
      "Last train loss of batch: 0.03289009630680084\n",
      "Train acc on batch: 0.9887671232876714\n",
      "Last train acc 0.98\n",
      "\n",
      "Test loss: 0.22661374509334564\n",
      "Test acc: 0.9564\n",
      "\n",
      "Valid loss: 0.19707724452018738\n",
      "Valid acc: 0.9634\n",
      "\n",
      "Epoch: 51\n",
      "Last train loss of batch: 0.03532647714018822\n",
      "Train acc on batch: 0.9897351598173516\n",
      "Last train acc 0.984\n",
      "\n",
      "Valid loss: 0.20584936439990997\n",
      "Valid acc: 0.9632\n",
      "\n",
      "Epoch: 52\n",
      "Last train loss of batch: 0.029214022681117058\n",
      "Train acc on batch: 0.9903561643835616\n",
      "Last train acc 0.984\n",
      "\n",
      "Valid loss: 0.20937590301036835\n",
      "Valid acc: 0.9634\n",
      "\n",
      "Epoch: 53\n",
      "Last train loss of batch: 0.0031119813211262226\n",
      "Train acc on batch: 0.9891872146118722\n",
      "Last train acc 1.0\n",
      "\n",
      "Valid loss: 0.23018866777420044\n",
      "Valid acc: 0.963\n",
      "\n",
      "Epoch: 54\n",
      "Last train loss of batch: 0.030259501188993454\n",
      "Train acc on batch: 0.9893881278538812\n",
      "Last train acc 0.992\n",
      "\n",
      "Valid loss: 0.22166763246059418\n",
      "Valid acc: 0.961\n",
      "\n",
      "Epoch: 55\n",
      "Last train loss of batch: 0.015866633504629135\n",
      "Train acc on batch: 0.9893515981735161\n",
      "Last train acc 0.992\n",
      "\n",
      "Test loss: 0.2591312527656555\n",
      "Test acc: 0.9555\n",
      "\n",
      "Valid loss: 0.2199324518442154\n",
      "Valid acc: 0.9636\n",
      "\n",
      "Epoch: 56\n",
      "Last train loss of batch: 0.012585899792611599\n",
      "Train acc on batch: 0.9910502283105024\n",
      "Last train acc 0.996\n",
      "\n",
      "Valid loss: 0.23704341053962708\n",
      "Valid acc: 0.9638\n",
      "\n",
      "Epoch: 57\n",
      "Last train loss of batch: 0.03751487657427788\n",
      "Train acc on batch: 0.990447488584475\n",
      "Last train acc 0.98\n",
      "\n",
      "Valid loss: 0.2240283191204071\n",
      "Valid acc: 0.9664\n",
      "\n",
      "Epoch: 58\n",
      "Last train loss of batch: 0.028804559260606766\n",
      "Train acc on batch: 0.9897899543378996\n",
      "Last train acc 0.992\n",
      "\n",
      "Valid loss: 0.2278691679239273\n",
      "Valid acc: 0.9636\n",
      "\n",
      "Epoch: 59\n",
      "Last train loss of batch: 0.04368908330798149\n",
      "Train acc on batch: 0.9908127853881279\n",
      "Last train acc 0.988\n",
      "\n",
      "Valid loss: 0.2221737802028656\n",
      "Valid acc: 0.9642\n",
      "\n",
      "Epoch: 60\n",
      "Last train loss of batch: 0.019000235944986343\n",
      "Train acc on batch: 0.9906484018264841\n",
      "Last train acc 0.992\n",
      "\n",
      "Test loss: 0.28136786818504333\n",
      "Test acc: 0.9536\n",
      "\n",
      "Valid loss: 0.23184585571289062\n",
      "Valid acc: 0.9658\n",
      "\n",
      "Epoch: 61\n",
      "Last train loss of batch: 0.021991081535816193\n",
      "Train acc on batch: 0.9876894977168948\n",
      "Last train acc 0.988\n",
      "\n",
      "Valid loss: 0.20278188586235046\n",
      "Valid acc: 0.9652\n",
      "\n",
      "Epoch: 62\n",
      "Last train loss of batch: 0.02580852620303631\n",
      "Train acc on batch: 0.9909041095890412\n",
      "Last train acc 0.992\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-98c92cc6d199>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mx_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_input_channel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;31m# compute losses and accuracy and save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fact/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-ef90eabd0e8d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m#encoder step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0menc_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fact/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-ef90eabd0e8d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mpad_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_l1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mpad_el1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fact/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fact/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fact/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    338\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    339\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 340\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = nn_prototype(15,4,10)\n",
    "batch_size_ = 250\n",
    "\n",
    "# get validation and test set\n",
    "valid_dl = DataLoader(valid_data, batch_size=5000, drop_last=False, shuffle=False)\n",
    "test_dl = DataLoader(test_data, batch_size=10000, drop_last=False, shuffle=False)\n",
    "\n",
    "\n",
    "# initialize optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# initialize storage for results\n",
    "train_accs = []\n",
    "train_losses = []\n",
    "test_accs = []\n",
    "test_losses = []\n",
    "valid_accs = []\n",
    "valid_losses = []\n",
    "\n",
    "# training loop\n",
    "for epoch in range(training_epochs):\n",
    "    print(\"\\nEpoch:\", epoch)\n",
    "\n",
    "    # load the training data and reshuffle\n",
    "    train_dl = DataLoader(train_data, batch_size=batch_size_, drop_last=False, shuffle=True)\n",
    "\n",
    "    # loop over the batches\n",
    "    for step, (x, Y) in enumerate(train_dl):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x_plot = x[0].clone()\n",
    "        \n",
    "        x = x.view(x.shape[0], n_input_channel, x.shape[1], x.shape[2]).float() / 255\n",
    "\n",
    "        #Y = Y.long()\n",
    "        \n",
    "        # perform forward pass\n",
    "        logits = model(x)\n",
    "\n",
    "        # compute the loss\n",
    "        total_loss = loss_function(logits, Y)\n",
    "\n",
    "        # backpropagate over the loss\n",
    "        total_loss.backward()\n",
    "\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # compute and save accuracy and loss\n",
    "        train_accuracy = compute_acc(logits, Y)\n",
    "        train_accs.append(train_accuracy)\n",
    "        train_losses.append(total_loss.item())\n",
    "\n",
    "\n",
    "    # print information after a batch\n",
    "    print('Last train loss of batch:', total_loss.item())\n",
    "    print('Train acc on batch:', np.mean(train_accs[-step:]))\n",
    "    print(\"Last train acc\", train_accuracy)\n",
    "\n",
    "\n",
    "    if epoch % test_display_step == 0:\n",
    "        # save model and prototypes\n",
    "        #torch.save(model, model_folder + \"/\" + model_filename + \"_epoch_\" + str(epoch) + '.pt')\n",
    "\n",
    "        \n",
    "        # perform testing\n",
    "        with torch.no_grad():\n",
    "            for (x_test, y_test) in test_dl:\n",
    "                x_test = x_test.view(x_test.shape[0], n_input_channel, x_test.shape[1], x_test.shape[2]).float() /255\n",
    "\n",
    "                # forward pass\n",
    "                logits = model(x_test)\n",
    "\n",
    "                # compute loss and accuracy and save\n",
    "                test_accuracy = compute_acc(logits, y_test)\n",
    "                test_loss = loss_function(logits, y_test)\n",
    "                test_accs.append(test_accuracy)\n",
    "                test_losses.append(test_loss)\n",
    "\n",
    "            print('\\nTest loss:', test_loss.item())\n",
    "            print('Test acc:', test_accuracy)\n",
    "\n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        for (x_valid, y_valid) in valid_dl:\n",
    "                x_valid = x_valid.view(x_valid.shape[0], n_input_channel, x_valid.shape[1], x_valid.shape[2]).float() /255\n",
    "        \n",
    "                logits = model(x_valid)\n",
    "\n",
    "                # compute losses and accuracy and save\n",
    "                valid_accuracy = compute_acc(logits, y_valid)\n",
    "                valid_loss = loss_function(logits, y_valid)\n",
    "                valid_accs.append(valid_accuracy)\n",
    "                valid_losses.append(valid_loss)\n",
    "\n",
    "        print('\\nValid loss:', valid_loss.item())\n",
    "        print('Valid acc:', valid_accuracy)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Final_notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
